{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Disasters: Twitter posts classification\n",
    "# ML Pipeline Preparation\n",
    "### by Javier Alonso\n",
    "\n",
    "In this project we analyze disaster data from [Figure Eight](https://www.figure-eight.com/dataset/combined-disaster-response-data/) to build a model that classifies disaster messages comming from Twitter.\n",
    "\n",
    "We have a data set containing real messages that were sent during disaster events. We will create a machine learning algorithm to categorize these events so that messages could be sent to an appropriate disaster relief agency.\n",
    "\n",
    "The dataset contains the original message in its original language, the English translation, and dozens of classes for message content. These classes are noted in column titles with a simple binary 1= yes, 0=no.\n",
    "\n",
    "In this notebook we prepare the Machine Learning Pipeline, once we´ve made the ETL in a prior notebook.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1.-[Gathering Data](#Gathering_Data)<br>\n",
    "2.-[Tokenization function](#Token_function)<br>\n",
    "3.-[Machine Learning Algorithm](#ML)<br>\n",
    "3.1-[Algorithm ranking](#ML_rank)<br>\n",
    "3.2-[Dimensional reduction](#ML_dim_rec)<br>\n",
    "3.3-[Get the best kernel](#ML_kernel)<br>\n",
    "3.4-[Get the best Gamma and C](#ML_GammaC)<br>\n",
    "3.5-[Final Model](#ML_Final_Model)<br>\n",
    "4.-[Further steps](#More_steps)<br>\n",
    "5.-[Model exportation](#Model_exp)<br>\n",
    "\n",
    "### <a class=\"anchor\" id=\"Gathering_Data\"> 1.- Gathering Data\n",
    "    \n",
    "- Import Python libraries\n",
    "- Load dataset from database \n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cance\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cance\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cance\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\cance\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet','stopwords', 'averaged_perceptron_tagger'])\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer,TfidfVectorizer \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models import Phrases\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "4        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from database\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table('Messages', 'sqlite:///NaturalDisastersMsgs.db') \n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "4        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language proccesing projects consume a lot of time so I´m going to get only a few columns, of different topics due to performance issues. \n",
    "The objective of this project is to know how to handle this type of projects, so at the end, it is the same doing it for all the  variables or just for a few. I choose the next 6 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['id','message','medical_help','water', 'food','clothing','missing_people','electricity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>clothing</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>electricity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  medical_help  water  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...             0      0   \n",
       "1   7            Is the Hurricane over or is it not over             0      0   \n",
       "2   8                    Looking for someone but no name             0      0   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...             0      0   \n",
       "4  12  says: west side of Haiti, rest of the country ...             0      0   \n",
       "\n",
       "   food  clothing  missing_people  electricity  \n",
       "0     0         0               0            0  \n",
       "1     0         0               0            0  \n",
       "2     0         0               0            0  \n",
       "3     0         0               0            0  \n",
       "4     0         0               0            0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical_help      2084\n",
       "water             1672\n",
       "food              2923\n",
       "clothing           405\n",
       "missing_people     298\n",
       "electricity        532\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['medical_help','water', 'food','clothing','missing_people','electricity']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"Token_function\"> 2.Tokenization function\n",
    "    \n",
    "I write the tokenization function to apply to the message column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    #case normalization\n",
    "    text = text.lower()\n",
    "    #split string into substrings\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    #delete stop words\n",
    "    tokens = [t for t in tokens if t not in stopwords.words(\"english\")]\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()        \n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    lemmed = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    clean_tokens = [stemmer.stem(l) for l in lemmed]    \n",
    "    \n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I test the function on five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather update - a cold front from Cuba that could pass over Haiti\n",
      "['weather', 'updat', 'cold', 'front', 'cuba', 'could', 'pa', 'haiti'] \n",
      "\n",
      "Is the Hurricane over or is it not over\n",
      "['hurrican'] \n",
      "\n",
      "Looking for someone but no name\n",
      "['look', 'someon', 'name'] \n",
      "\n",
      "UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.\n",
      "['un', 'report', 'leogan', '80', '90', 'destroy', 'hospit', 'st', 'croix', 'function', 'need', 'suppli', 'desper'] \n",
      "\n",
      "says: west side of Haiti, rest of the country today and tonight\n",
      "['say', 'west', 'side', 'haiti', 'rest', 'countri', 'today', 'tonight'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "for message in df.message[:5]:\n",
    "    tokens = tokenize(message)\n",
    "    print(message)\n",
    "    print(tokens, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'message', 'medical_help', 'water', 'food', 'clothing',\n",
       "       'missing_people', 'electricity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>clothing</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>electricity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  medical_help  water  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...             0      0   \n",
       "1   7            Is the Hurricane over or is it not over             0      0   \n",
       "2   8                    Looking for someone but no name             0      0   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...             0      0   \n",
       "4  12  says: west side of Haiti, rest of the country ...             0      0   \n",
       "\n",
       "   food  clothing  missing_people  electricity  \n",
       "0     0         0               0            0  \n",
       "1     0         0               0            0  \n",
       "2     0         0               0            0  \n",
       "3     0         0               0            0  \n",
       "4     0         0               0            0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I apply the function to the message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['msg_clean'] = df.message.map(lambda x: tokenize(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>clothing</th>\n",
       "      <th>missing_people</th>\n",
       "      <th>electricity</th>\n",
       "      <th>msg_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[weather, updat, cold, front, cuba, could, pa,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hurrican]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[look, someon, name]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[un, report, leogan, 80, 90, destroy, hospit, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[say, west, side, haiti, rest, countri, today,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  medical_help  water  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...             0      0   \n",
       "1   7            Is the Hurricane over or is it not over             0      0   \n",
       "2   8                    Looking for someone but no name             0      0   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...             0      0   \n",
       "4  12  says: west side of Haiti, rest of the country ...             0      0   \n",
       "\n",
       "   food  clothing  missing_people  electricity  \\\n",
       "0     0         0               0            0   \n",
       "1     0         0               0            0   \n",
       "2     0         0               0            0   \n",
       "3     0         0               0            0   \n",
       "4     0         0               0            0   \n",
       "\n",
       "                                           msg_clean  \n",
       "0  [weather, updat, cold, front, cuba, could, pa,...  \n",
       "1                                         [hurrican]  \n",
       "2                               [look, someon, name]  \n",
       "3  [un, report, leogan, 80, 90, destroy, hospit, ...  \n",
       "4  [say, west, side, haiti, rest, countri, today,...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a class=\"anchor\" id=\"ML\">3. Machine Learning algorithm\n",
    "This machine learning algorithm takes in the msg_clean column as input and output classification results on the 6 chosen categories of the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a class=\"anchor\" id=\"ML_rank\">3.1. Algorithm ranking\n",
    "Let´s try a few algorithms with default parameters to see which one works better and that´s the one that we will try to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26216, 55441)\n",
      "(26216, 6)\n"
     ]
    }
   ],
   "source": [
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['msg_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts) #features\n",
    "\n",
    "y = df[['medical_help','water','food','clothing','missing_people','electricity']]\n",
    "\n",
    "print (X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 100)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimenionality reduction. Only using the 100 best features per category, as a first approach\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "X = lsa.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary model evaluation using default parameters\n",
    "\n",
    "#Creating a dict of the models\n",
    "model = {'Logistic Regression' : MultiOutputClassifier(LogisticRegression()),\n",
    "              'SVC' : MultiOutputClassifier(SVC()),\n",
    "              'KNN': MultiOutputClassifier(KNeighborsClassifier(n_neighbors = 3)),\n",
    "              'GaussianNB': MultiOutputClassifier(GaussianNB()),\n",
    "              'Perceptron': MultiOutputClassifier(Perceptron()),\n",
    "              'SGP': MultiOutputClassifier(SGDClassifier()),\n",
    "              'Random Forest': MultiOutputClassifier(RandomForestClassifier(n_estimators=100)),\n",
    "              'Adaboost': MultiOutputClassifier(AdaBoostClassifier(n_estimators=100)),\n",
    "              'linear svc': MultiOutputClassifier(LinearSVC())}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .2, \n",
    "                                                    shuffle = True, \n",
    "                                                    random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 7.5 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>f1_medical_help</th>\n",
       "      <th>f1_water</th>\n",
       "      <th>f1_food</th>\n",
       "      <th>f1_clothing</th>\n",
       "      <th>f1_missing_people</th>\n",
       "      <th>f1_electricity</th>\n",
       "      <th>f1_micro_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.207436</td>\n",
       "      <td>0.686971</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.557715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adaboost</td>\n",
       "      <td>0.355987</td>\n",
       "      <td>0.675241</td>\n",
       "      <td>0.653595</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.351515</td>\n",
       "      <td>0.538663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>linear svc</td>\n",
       "      <td>0.260073</td>\n",
       "      <td>0.660839</td>\n",
       "      <td>0.693994</td>\n",
       "      <td>0.288462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118644</td>\n",
       "      <td>0.525631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.049438</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.702143</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.427907</td>\n",
       "      <td>0.511594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672355</td>\n",
       "      <td>0.724046</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.178926</td>\n",
       "      <td>0.603291</td>\n",
       "      <td>0.645355</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.476759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.198807</td>\n",
       "      <td>0.595104</td>\n",
       "      <td>0.637205</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.463628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.213523</td>\n",
       "      <td>0.554717</td>\n",
       "      <td>0.579003</td>\n",
       "      <td>0.342342</td>\n",
       "      <td>0.027397</td>\n",
       "      <td>0.248276</td>\n",
       "      <td>0.438240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.192574</td>\n",
       "      <td>0.516201</td>\n",
       "      <td>0.441158</td>\n",
       "      <td>0.252492</td>\n",
       "      <td>0.035623</td>\n",
       "      <td>0.075402</td>\n",
       "      <td>0.205581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  f1_medical_help  f1_water   f1_food  f1_clothing  \\\n",
       "1                  SVC         0.207436  0.686971  0.745098     0.378378   \n",
       "7             Adaboost         0.355987  0.675241  0.653595     0.352000   \n",
       "8           linear svc         0.260073  0.660839  0.693994     0.288462   \n",
       "4           Perceptron         0.049438  0.540000  0.702143     0.438202   \n",
       "5                  SGP         0.000000  0.672355  0.724046     0.068966   \n",
       "6        Random Forest         0.178926  0.603291  0.645355     0.297030   \n",
       "0  Logistic Regression         0.198807  0.595104  0.637205     0.187500   \n",
       "2                  KNN         0.213523  0.554717  0.579003     0.342342   \n",
       "3           GaussianNB         0.192574  0.516201  0.441158     0.252492   \n",
       "\n",
       "   f1_missing_people  f1_electricity  f1_micro_avg  \n",
       "1           0.000000        0.136752      0.557715  \n",
       "7           0.000000        0.351515      0.538663  \n",
       "8           0.000000        0.118644      0.525631  \n",
       "4           0.000000        0.427907      0.511594  \n",
       "5           0.000000        0.000000      0.505403  \n",
       "6           0.000000        0.178862      0.476759  \n",
       "0           0.000000        0.036364      0.463628  \n",
       "2           0.027397        0.248276      0.438240  \n",
       "3           0.035623        0.075402      0.205581  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_score(model_dict):\n",
    "    start_time = time.time()\n",
    "    model_name,  f1_score_list = [], []\n",
    "    model_comparison_df = pd.DataFrame(columns=['model_name', 'f1_medical_help', 'f1_water', 'f1_food', 'f1_clothing', 'f1_missing_people', 'f1_electricity', 'f1_micro_avg'])       \n",
    "    i = 0\n",
    "    for k,v in model.items():\n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True,zero_division= 0  )\n",
    "        df_rep = pd.DataFrame(report)\n",
    "        df_rep = df_rep[['0','1','2','3','4','5', 'micro avg']].iloc[2]\n",
    "        model_comparison_df.loc[i] = [model_name[i], df_rep[0], df_rep[1], df_rep[2], df_rep[3], df_rep[4], df_rep[5], df_rep[6]]\n",
    "        i = i+1\n",
    "    model_comparison_df = model_comparison_df.sort_values(by='f1_micro_avg', ascending=False)\n",
    "    exec_time = round((time.time() - start_time)/60,2)\n",
    "    print(\"Execution time:\",exec_time,\"minutes\")\n",
    "    return model_comparison_df\n",
    "model_score(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see SVC is the one with best average performance, but not the best in all the variables\n",
    "\n",
    "We can see that is almost impossible to classify twits in the cathegory of missing people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a class=\"anchor\" id=\"ML_dim_rec\">3.2. Dimensional reduction\n",
    "The dataset has 55441 columns as input variables and this is impossible to handle. As a first step I reduced to 100 dimensions but let´s check if it´s a good approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 17.61 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "texts = df['msg_clean'].astype('str')\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "y = df[['medical_help','water','food','clothing','missing_people','electricity']]\n",
    "\n",
    "components = [100,200,250,300]\n",
    "\n",
    "model_comparison_df = pd.DataFrame(columns=['n_components', 'f1_medical_help', 'f1_water', 'f1_food', 'f1_clothing', 'f1_missing_people', 'f1_electricity', 'f1_micro_avg','time'])       \n",
    "\n",
    "j = 0\n",
    "for i in components:\n",
    "    time0 = time.time()\n",
    "    X = tfidf_vectorizer.fit_transform(texts) #features\n",
    "    \n",
    "    lsa = TruncatedSVD(n_components=i, \n",
    "                       n_iter=10, \n",
    "                       random_state=3)\n",
    "    X = lsa.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = .2, \n",
    "                                                        shuffle = True, \n",
    "                                                        random_state = 3)\n",
    "    model = MultiOutputClassifier(SVC())\n",
    "\n",
    "    n_components,  f1_score_list = [], []\n",
    "    \n",
    "    n_components.append(i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True,zero_division= 0  )\n",
    "    df_rep = pd.DataFrame(report)\n",
    "    df_rep = df_rep[['0','1','2','3','4','5', 'micro avg']].iloc[2]\n",
    "    timef = round((time.time() - time0)/60,2)\n",
    "    model_comparison_df.loc[j] = [components[j], df_rep[0], df_rep[1], df_rep[2], df_rep[3], df_rep[4], df_rep[5], df_rep[6], timef]\n",
    "    j = j+1\n",
    "\n",
    "model_comparison_df = model_comparison_df.sort_values(by='n_components', ascending=True)\n",
    "         \n",
    "exec_time = round((time.time() - start_time)/60,2)\n",
    "print(\"Execution time:\",exec_time,\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_components</th>\n",
       "      <th>f1_medical_help</th>\n",
       "      <th>f1_water</th>\n",
       "      <th>f1_food</th>\n",
       "      <th>f1_clothing</th>\n",
       "      <th>f1_missing_people</th>\n",
       "      <th>f1_electricity</th>\n",
       "      <th>f1_micro_avg</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.207436</td>\n",
       "      <td>0.686971</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.557715</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.247148</td>\n",
       "      <td>0.690236</td>\n",
       "      <td>0.761233</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.580420</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.273408</td>\n",
       "      <td>0.695946</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.593449</td>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300.0</td>\n",
       "      <td>0.288355</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>0.771105</td>\n",
       "      <td>0.562963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.599388</td>\n",
       "      <td>6.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_components  f1_medical_help  f1_water   f1_food  f1_clothing  \\\n",
       "0         100.0         0.207436  0.686971  0.745098     0.378378   \n",
       "1         200.0         0.247148  0.690236  0.761233     0.535433   \n",
       "2         250.0         0.273408  0.695946  0.769231     0.575758   \n",
       "3         300.0         0.288355  0.707071  0.771105     0.562963   \n",
       "\n",
       "   f1_missing_people  f1_electricity  f1_micro_avg  time  \n",
       "0                0.0        0.136752      0.557715  1.66  \n",
       "1                0.0        0.178862      0.580420  4.14  \n",
       "2                0.0        0.209677      0.593449  5.12  \n",
       "3                0.0        0.234375      0.599388  6.70  "
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAUcklEQVR4nO3df6zdd33f8edrN05wxTZDc5kSx8ymdSLQiBJyGqEx2kIXbNjqpASx0E0j2iD7IYtNE9YSVdq6TBWjVqeqUjSWsGjpVEholhpnGjWBpazqGurjOiTYrpc7sy7XjuA2waUML4nDe3/c74Xjk2Pfc5zre+xPng/p6J7v5/v5nu/7fO9Hr/M9n/O996SqkCS1689NuwBJ0rll0EtS4wx6SWqcQS9JjTPoJalxF027gGGXXnppbdy4cdplSNIFZd++fX9SVbOj1p13Qb9x40b6/f60y5CkC0qSPz7dOqduJKlxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1Ljxgr6JFuTHE4yl+T20/T5YJKDSQ4k+cxA+28nOZ7kv6xU0ZKk8S37/+iTzAB3ATcA88DeJLur6uBAn83AHcA7qurbSd4w8BA7gR8B/sGKVi5JGss4Z/TXA3NVdaSqXgDuB24c6vNR4K6q+jZAVX1raUVVfRn4sxWqV5I0oXGCfj3w9MDyfNc26ErgyiS/l+SxJFsnKSLJbUn6SfoLCwuTbCpJWsY4QZ8RbTW0fBGwGfhp4EPAp5OsG7eIqrq7qnpV1ZudHfmVh5KkszRO0M8DGwaWrwCOjejz+ap6saq+ARxmMfglSVM2TtDvBTYn2ZTkYuAWYPdQn13AuwCSXMriVM6RlSxUknR2lg36qjoJbAf2AIeAz1XVgSR3JtnWddsDPJvkIPAosKOqngVI8rvAbwI/k2Q+yZZz8UQkSaOlani6fbp6vV71+/1plyFJF5Qk+6qqN2qdfxkrSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGjRX0SbYmOZxkLsntp+nzwSQHkxxI8pmB9g8neaq7fXilCpckjeei5TokmQHuAm4A5oG9SXZX1cGBPpuBO4B3VNW3k7yha3898C+BHlDAvm7bb6/8U5EkjbJs0APXA3NVdQQgyf3AjcDBgT4fBe5aCvCq+lbXvgV4pKqe67Z9BNgKfHZlypekC9+u/UfZuecwx46f4PJ1a9mx5Spuunb9ij3+OFM364GnB5bnu7ZBVwJXJvm9JI8l2TrBtiS5LUk/SX9hYWH86iXpArdr/1HueOhJjh4/QQFHj5/gjoeeZNf+oyu2j3GCPiPaamj5ImAz8NPAh4BPJ1k35rZU1d1V1auq3uzs7BglSVIbdu45zIkXXzql7cSLL7Fzz+EV28c4QT8PbBhYvgI4NqLP56vqxar6BnCYxeAfZ1tJetU6dvzERO1nY5yg3wtsTrIpycXALcDuoT67gHcBJLmUxamcI8Ae4D1JXpfkdcB7ujZJEnD5urUTtZ+NZYO+qk4C21kM6EPA56rqQJI7k2zruu0Bnk1yEHgU2FFVz3Yfwv5rFl8s9gJ3Ln0wK0mCHVuuYu2amVPa1q6ZYceWq1ZsH6l62ZT5VPV6ver3+9MuQ5JWzUpcdZNkX1X1Rq0b5/JKSdI5dNO161f0csph/gsESWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnH8ZK2nFnesv0tBkDHpJK2rpizSW/sf60hdpAIb9lDh1I2lFrcYXaWgyBr2kFbUaX6ShyRj0klbUanyRhiZj0EtaUavxRRqajB/GSlpRSx+4etXN+cOgl7TizvUXaWgyTt1IUuPGCvokW5McTjKX5PYR629NspDk8e72kYF1n0zy9e72t1ayeEnS8padukkyA9wF3ADMA3uT7K6qg0NdH6iq7UPb/g3gbcA1wCXAV5J8oaq+syLVS5KWNc4Z/fXAXFUdqaoXgPuBG8d8/LcAX6mqk1X1f4GvAVvPrlRJ0tkYJ+jXA08PLM93bcNuTvJEkgeTbOjavga8N8mPJLkUeBewYXjDJLcl6SfpLywsTPgUJElnMk7QZ0RbDS0/DGysqquBLwH3AVTVF4H/CvwP4LPA7wMnX/ZgVXdXVa+qerOzsxOUL0lazjhBP8+pZ+FXAMcGO1TVs1X1fLd4D3DdwLpfqqprquoGFl80nnplJUuSJjFO0O8FNifZlORi4BZg92CHJJcNLG4DDnXtM0l+tLt/NXA18MWVKFySNJ5lr7qpqpNJtgN7gBng3qo6kOROoF9Vu4GPJdnG4rTMc8Ct3eZrgN9NAvAd4O9U1cumbiRJ506qhqfbp6vX61W/3592GZJ0QUmyr6p6o9b5l7GS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS45b9cnBJsGv/UXbuOcyx4ye4fN1admy5ipuuXT/tsqSxjHVGn2RrksNJ5pLcPmL9rUkWkjze3T4ysO6XkxxIcijJryXJSj4B6Vzbtf8odzz0JEePn6CAo8dPcMdDT7Jr/9FplyaNZdmgTzID3AW8F3gL8KEkbxnR9YGquqa7fbrb9q8C7wCuBv4K8BPAT61U8dJq2LnnMCdefOmUthMvvsTOPYenVJE0mXHO6K8H5qrqSFW9ANwP3Djm4xfwGuBi4BJgDfDNsylUmpZjx09M1C6db8YJ+vXA0wPL813bsJuTPJHkwSQbAKrq94FHgWe6256qOjS8YZLbkvST9BcWFiZ+EtK5dPm6tRO1S+ebcYJ+1Jx6DS0/DGysqquBLwH3AST5ceDNwBUsvji8O8lPvuzBqu6uql5V9WZnZyepXzrndmy5irVrZk5pW7tmhh1brppSRdJkxgn6eWDDwPIVwLHBDlX1bFU93y3eA1zX3f854LGq+m5VfRf4AvD2V1aytLpuunY9n3j/W1m/bi0B1q9byyfe/1avutEFY5zLK/cCm5NsAo4CtwA/P9ghyWVV9Uy3uA1Ymp75P8BHk3yCxXcGPwX86koULq2mm65db7DrgrVs0FfVySTbgT3ADHBvVR1IcifQr6rdwMeSbANOAs8Bt3abPwi8G3iSxeme366qh1f+aUiSTidVw9Pt09Xr9arf70+7DEm6oCTZV1W9Uev8FwiS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS48YK+iRbkxxOMpfk9hHrb02ykOTx7vaRrv1dA22PJ/l/SW5a6SchSTq9i5brkGQGuAu4AZgH9ibZXVUHh7o+UFXbBxuq6lHgmu5xXg/MAV9cicIlSeMZ54z+emCuqo5U1QvA/cCNZ7GvDwBfqKrvncW2kqSzNE7QrweeHlie79qG3ZzkiSQPJtkwYv0twGdH7SDJbUn6SfoLCwtjlCRJGtc4QZ8RbTW0/DCwsaquBr4E3HfKAySXAW8F9ozaQVXdXVW9qurNzs6OUZIkaVzjBP08MHiGfgVwbLBDVT1bVc93i/cA1w09xgeB36qqF8+2UEnS2Rkn6PcCm5NsSnIxi1Mwuwc7dGfsS7YBh4Ye40OcZtpGknRuLXvVTVWdTLKdxWmXGeDeqjqQ5E6gX1W7gY8l2QacBJ4Dbl3aPslGFt8RfGXFq5ckLStVw9Pt09Xr9arf70+7DEm6oCTZV1W9Uev8y1hJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDVurKBPsjXJ4SRzSW4fsf7WJAtJHu9uHxlY98YkX0xyKMnBJBtXrnxJ0nIuWq5DkhngLuAGYB7Ym2R3VR0c6vpAVW0f8RC/DvxSVT2S5LXA919p0ZKk8Y1zRn89MFdVR6rqBeB+4MZxHjzJW4CLquoRgKr6blV976yrlSRNbJygXw88PbA837UNuznJE0keTLKha7sSOJ7koST7k+zs3iGcIsltSfpJ+gsLCxM/CUnS6Y0T9BnRVkPLDwMbq+pq4EvAfV37RcA7gY8DPwG8Cbj1ZQ9WdXdV9aqqNzs7O2bpkqRxjBP088CGgeUrgGODHarq2ap6vlu8B7huYNv93bTPSWAX8LZXVrIkaRLjBP1eYHOSTUkuBm4Bdg92SHLZwOI24NDAtq9LsnSa/m5g+ENcSdI5tOxVN1V1Msl2YA8wA9xbVQeS3An0q2o38LEk24CTwHN00zNV9VKSjwNfThJgH4tn/Ctu1/6j7NxzmGPHT3D5urXs2HIVN1076qMESXp1SdXwdPt09Xq96vf7E22za/9R7njoSU68+NIP2taumeET73+rYS/pVSHJvqrqjVrXxF/G7txz+JSQBzjx4kvs3HN4ShVJ0vmjiaA/dvzERO2S9GrSRNBfvm7tRO2S9GrSRNDv2HIVa9ec+ndYa9fMsGPLVVOqSJLOH8tedXMhWPrA1atuJOnlmgh6WAx7g12SXq6JqRtJ0ukZ9JLUOINekhpn0EtS4wx6SWqcQS9JjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklq3FhBn2RrksNJ5pLcPmL9rUkWkjze3T4ysO6lgfbdK1m8JGl5y/6b4iQzwF3ADcA8sDfJ7qo6ONT1garaPuIhTlTVNa+8VEnS2RjnjP56YK6qjlTVC8D9wI3ntixJ0koZJ+jXA08PLM93bcNuTvJEkgeTbBhof02SfpLHktz0SoqVJE1unKDPiLYaWn4Y2FhVVwNfAu4bWPfGquoBPw/8apIfe9kOktu6F4P+wsLCmKVLksYxTtDPA4Nn6FcAxwY7VNWzVfV8t3gPcN3AumPdzyPA7wDXDu+gqu6uql5V9WZnZyd6ApKkMxsn6PcCm5NsSnIxcAtwytUzSS4bWNwGHOraX5fkku7+pcA7gOEPcSVJ59CyV91U1ckk24E9wAxwb1UdSHIn0K+q3cDHkmwDTgLPAbd2m78Z+PdJvs/ii8q/GXG1jiTpHErV8HT7dPV6ver3+9MuQ5IuKEn2dZ+Hvox/GStJjTPoJalxBr0kNc6gl6TGGfSS1DiDXpIaZ9BLUuMMeklqnEEvSY0z6CWpcQa9JDXOoJekxhn0ktQ4g16SGmfQS1LjDHpJapxBL0mNM+glqXEGvSQ1zqCXpMYZ9JLUOINekhqXqpp2DadIsgD88St4iEuBP1mhclaSdU3GuiZjXZNpsa6/XFWzo1acd0H/SiXpV1Vv2nUMs67JWNdkrGsyr7a6nLqRpMYZ9JLUuBaD/u5pF3Aa1jUZ65qMdU3mVVVXc3P0kqRTtXhGL0kaYNBLUuMuqKBPcm+SbyX5+kDb65M8kuSp7ufruvYk+bUkc0meSPK2Va5rZ5I/6vb9W0nWde0bk5xI8nh3+9Qq1/WLSY4O7P99A+vu6I7X4SRbVrmuBwZq+t9JHu/aV/N4bUjyaJJDSQ4k+Sdd+1TH2BnqmuoYO0NdUx1jZ6hrqmMsyWuS/EGSr3V1/auufVOSr3bj64EkF3ftl3TLc936jWe986q6YG7ATwJvA74+0PbLwO3d/duBT3b33wd8AQjwduCrq1zXe4CLuvufHKhr42C/KRyvXwQ+PqLvW4CvAZcAm4D/BcysVl1D638F+BdTOF6XAW/r7v954H92x2WqY+wMdU11jJ2hrqmOsdPVNe0x1o2T13b31wBf7cbN54BbuvZPAf+ou/+PgU91928BHjjbfV9QZ/RV9d+B54aabwTu6+7fB9w00P7rtegxYF2Sy1arrqr6YlWd7BYfA644F/uetK4zuBG4v6qer6pvAHPA9atdV5IAHwQ+ey72fSZV9UxV/WF3/8+AQ8B6pjzGTlfXtMfYGY7X6azKGFuurmmNsW6cfLdbXNPdCng38GDXPjy+lsbdg8DPdLVP7IIK+tP4S1X1DCz+goE3dO3rgacH+s1z5kF4Lv09Fs/8lmxKsj/JV5K8cwr1bO/e7t+7NA3B+XO83gl8s6qeGmhb9ePVvU2+lsWzrvNmjA3VNWiqY2xEXefFGDvN8ZraGEsy000ZfQt4hMV3NccHXrAHj8kPjle3/k+BHz2b/bYQ9Kcz6pVv1a8lTfILwEngN7qmZ4A3VtW1wD8DPpPkL6xiSf8O+DHgmq6WX1kqdUTfaVx7+yFOPdNa9eOV5LXAfwb+aVV950xdR7Sds2N2urqmPcZG1HVejLEz/B6nNsaq6qWquobFd1/XA28e1a37uWLHq4Wg/+bS2+Xu57e69nlgw0C/K4Bjq1lYkg8DfxP429VNtHVvW5/t7u9j8RX9ytWqqaq+2Q227wP38MO3zufD8boIeD/wwFLbah+vJGtYDIffqKqHuuapj7HT1DX1MTaqrvNhjJ3heE19jHX7OQ78Dotz9Ou6uuDUY/KD49Wt/4uMPxV7ihaCfjfw4e7+h4HPD7T/3Sx6O/CnS2+/V0OSrcA/B7ZV1fcG2meTzHT33wRsBo6sYl2Dc8g/Byxd+bIbuKX7pH9TV9cfrFZdnb8O/FFVzS81rObx6uY//wNwqKr+7cCqqY6x09U17TF2hrqmOsbO8HuEKY6xbj9LV0at7Wo5BDwKfKDrNjy+lsbdB4D/tvRiPrGz/RR3GjcW3249A7zI4qvd32dxzurLwFPdz9fXDz/hvovFV+cngd4q1zXH4vza491t6dPzm4EDLF598IfAz65yXf+pOx5PdAPpsoH+v9Adr8PAe1ezrq79PwL/cKjvah6vv8biW+MnBn5v75v2GDtDXVMdY2eoa6pj7HR1TXuMAVcD+7u6vs4Pr/p5E4sveHPAbwKXdO2v6ZbnuvVvOtt9+y8QJKlxLUzdSJLOwKCXpMYZ9JLUOINekhpn0EtS4wx6SWqcQS9Jjfv/F1dx8B32ZmUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(model_comparison_df.n_components, model_comparison_df.f1_micro_avg);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As more components exist there are better results, but, on the other hand, the relative gain descends and performance time gets higher. \n",
    "We need to get a compromise between execution time and results, and I think the best option is 250 components, but due to time consumption we´ll do all next tests with 100 dimensions, doing a final test with 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. <a class=\"anchor\" id=\"ML_kernel\">Get the best kernel\n",
    "I´m going to use grid search to find the best kernel and then try to improve it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['medical_help','water','food','clothing','missing_people','electricity']]\n",
    "X = df['msg_clean'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "texts = df['msg_clean'].astype('str')\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "y = df[['medical_help','water','food','clothing','missing_people','electricity']]\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts) #features\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "X = lsa.fit_transform(X)\n",
    "\n",
    "exec_time = round((time.time() - start_time)/60,2)\n",
    "print(exec_time,\"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.16 mins\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', MultiOutputClassifier(SVC()))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "#SVC\n",
    "kernel =  ['linear', 'poly', 'rbf']\n",
    "# gammas = [0.1]\n",
    "# penalty = ['l2','l1']\n",
    "# alpha = [1e-6, 1e-3, 1e-1, 1e0]\n",
    "# max_iter = [5, 1000, 10000]\n",
    "# tol = [None, 1e-3]\n",
    "# eta0 = [0.1, 0.001]\n",
    "\n",
    "random_state = [3]\n",
    "\n",
    "clf = MultiOutputClassifier(SVC())\n",
    "\n",
    "\n",
    "params = {'clf__estimator__kernel': kernel}\n",
    "\n",
    "# cv = GridSearchCV(MultiOutputClassifier(SVC()), param_grid=params)\n",
    "cv = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "cv.fit(X, y)\n",
    "exec_time = round((time.time() - start_time)/60,2)\n",
    "print(exec_time,\"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'clf__estimator__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([24.55321865, 72.85069952, 78.05022955]),\n",
       " 'std_fit_time': array([ 1.79831467,  7.89592028, 11.90508962]),\n",
       " 'mean_score_time': array([ 4.3629045 ,  7.89175096, 10.51993952]),\n",
       " 'std_score_time': array([0.31107438, 0.37554641, 0.81905384]),\n",
       " 'param_clf__estimator__kernel': masked_array(data=['linear', 'poly', 'rbf'],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__estimator__kernel': 'linear'},\n",
       "  {'clf__estimator__kernel': 'poly'},\n",
       "  {'clf__estimator__kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.7921434 , 0.7791762 , 0.78832952]),\n",
       " 'split1_test_score': array([0.92427999, 0.89586115, 0.92065611]),\n",
       " 'split2_test_score': array([0.78733549, 0.78447454, 0.79267595]),\n",
       " 'split3_test_score': array([0.77875262, 0.77894335, 0.79191303]),\n",
       " 'split4_test_score': array([0.75433912, 0.76158688, 0.77207706]),\n",
       " 'mean_test_score': array([0.80737013, 0.80000842, 0.81313033]),\n",
       " 'std_test_score': array([0.05988724, 0.04854478, 0.05427854]),\n",
       " 'rank_test_score': array([2, 3, 1])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best kernel is rbf, so the best option at the moment, is SVC with 250 dimensions reduction and rbf kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. <a class=\"anchor\" id=\"ML_GammaC\"> Get the best Gamma and C\n",
    "I´m going to use grid search to find better parameters of Gamma and C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.68 mins\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('clf', MultiOutputClassifier(SVC(kernel = 'rbf', random_state = 3 )))\n",
    "])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gammas = [0.1, 1, 10]\n",
    "cs = [0.1, 1, 10]\n",
    "\n",
    "\n",
    "\n",
    "params = {'clf__estimator__gamma': gammas,\n",
    "         'clf__estimator__C': cs}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=params)\n",
    "\n",
    "cv.fit(X, y)\n",
    "exec_time = round((time.time() - start_time)/60,2)\n",
    "print(exec_time,\"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters: {'clf__estimator__C': 10, 'clf__estimator__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 35.79060836,  36.74275794,  59.83446417,  34.21952448,\n",
       "         39.66700563,  92.39224119,  45.53900027,  45.40631652,\n",
       "        147.11864271]),\n",
       " 'std_fit_time': array([ 3.81360972,  2.66637492,  7.03543014,  2.25386384,  1.76775879,\n",
       "        13.86148152,  3.24161962,  2.92746236, 17.77885043]),\n",
       " 'mean_score_time': array([  7.10308452,   7.08826251,  10.12737212,   6.55986166,\n",
       "          6.77412734, 749.13589907,   7.08155861,   6.99137878,\n",
       "         11.41080394]),\n",
       " 'std_score_time': array([7.35019520e-01, 4.27946572e-01, 8.21485301e-01, 4.22681151e-01,\n",
       "        3.71091638e-01, 1.47620377e+03, 4.36371822e-01, 3.89348741e-01,\n",
       "        8.88823898e-01]),\n",
       " 'param_clf__estimator__C': masked_array(data=[0.1, 0.1, 0.1, 1, 1, 1, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__gamma': masked_array(data=[0.1, 1, 10, 0.1, 1, 10, 0.1, 1, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__estimator__C': 0.1, 'clf__estimator__gamma': 0.1},\n",
       "  {'clf__estimator__C': 0.1, 'clf__estimator__gamma': 1},\n",
       "  {'clf__estimator__C': 0.1, 'clf__estimator__gamma': 10},\n",
       "  {'clf__estimator__C': 1, 'clf__estimator__gamma': 0.1},\n",
       "  {'clf__estimator__C': 1, 'clf__estimator__gamma': 1},\n",
       "  {'clf__estimator__C': 1, 'clf__estimator__gamma': 10},\n",
       "  {'clf__estimator__C': 10, 'clf__estimator__gamma': 0.1},\n",
       "  {'clf__estimator__C': 10, 'clf__estimator__gamma': 1},\n",
       "  {'clf__estimator__C': 10, 'clf__estimator__gamma': 10}],\n",
       " 'split0_test_score': array([0.69889397, 0.73474447, 0.72254005, 0.74103738, 0.80072464,\n",
       "        0.7890923 , 0.79843631, 0.81655225, 0.78318078]),\n",
       " 'split1_test_score': array([0.89109289, 0.92084684, 0.90921228, 0.9212283 , 0.92504291,\n",
       "        0.92141903, 0.92466145, 0.93019264, 0.90864009]),\n",
       " 'split2_test_score': array([0.76788098, 0.78218577, 0.78619111, 0.78447454, 0.79076864,\n",
       "        0.79305741, 0.78771696, 0.79420179, 0.79839786]),\n",
       " 'split3_test_score': array([0.76864391, 0.77741751, 0.78008774, 0.77760824, 0.78199504,\n",
       "        0.79572764, 0.77951554, 0.78638184, 0.79916079]),\n",
       " 'split4_test_score': array([0.75090597, 0.75586496, 0.75891665, 0.75510204, 0.75681862,\n",
       "        0.77684532, 0.75414839, 0.76616441, 0.7760824 ]),\n",
       " 'mean_test_score': array([0.77548354, 0.79421191, 0.79138957, 0.7958901 , 0.81106997,\n",
       "        0.81522834, 0.80889573, 0.81869859, 0.81309238]),\n",
       " 'std_test_score': array([0.0631508 , 0.06552855, 0.06297888, 0.06457042, 0.05881762,\n",
       "        0.05348764, 0.05969943, 0.05803419, 0.04858771]),\n",
       " 'rank_test_score': array([9, 7, 8, 6, 4, 2, 5, 1, 3])}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best are C= 10 and gamma = 1. Look that it took almost 2 hours to do the gridsearch of parameters.\n",
    "\n",
    "So the best model is SVC with 250 parameters reduction, with kernel rbf, C =10 and gamma = 1. I´m going to test it as we did in the beginning to see the performance\n",
    "\n",
    "#### 3.5. <a class=\"anchor\" id=\"ML_Final_Model\"> Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18 mins\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['msg_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "X = tfidf_vectorizer.fit_transform(texts) #features\n",
    "y = df[['medical_help','water','food','clothing','missing_people','electricity']]\n",
    "\n",
    "lsa = TruncatedSVD(n_components=250, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "X = lsa.fit_transform(X)\n",
    "\n",
    "exec_time = round((time.time() - start_time)/60,2)\n",
    "print(exec_time,\"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26216, 250)\n",
      "(26216, 6)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary model evaluation using default parameters\n",
    "\n",
    "#Creating a dict of the models\n",
    "model = {'SVC' : MultiOutputClassifier(SVC(kernel = 'rbf', random_state = 3, C= 10, gamma = 1))}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .2, \n",
    "                                                    shuffle = True, \n",
    "                                                    random_state = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 2.55 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>f1_medical_help</th>\n",
       "      <th>f1_water</th>\n",
       "      <th>f1_food</th>\n",
       "      <th>f1_clothing</th>\n",
       "      <th>f1_missing_people</th>\n",
       "      <th>f1_electricity</th>\n",
       "      <th>f1_micro_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>0.74359</td>\n",
       "      <td>0.794937</td>\n",
       "      <td>0.57971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283582</td>\n",
       "      <td>0.626248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  f1_medical_help  f1_water   f1_food  f1_clothing  \\\n",
       "0        SVC         0.306306   0.74359  0.794937      0.57971   \n",
       "\n",
       "   f1_missing_people  f1_electricity  f1_micro_avg  \n",
       "0                0.0        0.283582      0.626248  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_score(model_dict):\n",
    "    start_time = time.time()\n",
    "    model_name,  f1_score_list = [], []\n",
    "    model_comparison_df = pd.DataFrame(columns=['model_name', 'f1_medical_help', 'f1_water', 'f1_food', 'f1_clothing', 'f1_missing_people', 'f1_electricity', 'f1_micro_avg'])       \n",
    "    i = 0\n",
    "    for k,v in model.items():\n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True,zero_division= 0  )\n",
    "        df_rep = pd.DataFrame(report)\n",
    "        df_rep = df_rep[['0','1','2','3','4','5', 'micro avg']].iloc[2]\n",
    "        model_comparison_df.loc[i] = [model_name[i], df_rep[0], df_rep[1], df_rep[2], df_rep[3], df_rep[4], df_rep[5], df_rep[6]]\n",
    "        i = i+1\n",
    "    model_comparison_df = model_comparison_df.sort_values(by='f1_micro_avg', ascending=False)\n",
    "    exec_time = round((time.time() - start_time)/60,2)\n",
    "    print(\"Execution time:\",exec_time,\"minutes\")\n",
    "    return model_comparison_df\n",
    "model_score(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVC with default parameters and 100 dimensions reduction score was 0.55, and with 250 dimensions was 0.59. \n",
    "\n",
    "Tuning the parameters we´ve been able to increase the f1 score to 0.63...Great job!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. <a class=\"anchor\" id=\"More_steps\">Further steps\n",
    "Having more computational power would allow us to do a better gridsearch parameters finding and keeping more parameters. This could be made on the cloud, but it is out of the scope in this project. Also, with actual performance, we can´t try to predict the original 36 output variables.\n",
    "With actual hardware (local laptop) there are still some other ways to improve the model:\n",
    "- try other algorithms. SVC was the best with default parameters but other algorithm could increase the performance with the parameters tuning\n",
    "- try other features. We´ve used TfidfVectorizer to extract the features from the text, but there are other options like Word2vec or Glove, that could be a good alternative\n",
    "- some of the variables, like electricity, clothing,missing or medical help, are better predicted with different algorithms than SVC. If we want to priorize one of these we could change the algorithm or even divide the objective variables in groups to predict them differently\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. <a class=\"anchor\" id=\"Model_exp\">Model exportation\n",
    "I extract the model to a file in case we wan to use it in other place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('finalized_model.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
